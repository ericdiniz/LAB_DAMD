# Roteiro 4: Arquitetura Serverless com LocalStack

**LaboratÃ³rio de Desenvolvimento de AplicaÃ§Ãµes MÃ³veis e DistribuÃ­das**  
**Curso de Engenharia de Software - PUC Minas**  
**Professores:** Artur Mol, Cleiton Tavares e Cristiano Neto

---

## Objetivos

- Compreender os fundamentos da arquitetura serverless
- Implementar funÃ§Ãµes Lambda com Node.js usando Serverless Framework
- Desenvolver pipeline de processamento de dados event-driven
- Integrar serviÃ§os AWS (S3, DynamoDB, SNS) usando LocalStack
- Comparar arquiteturas serverless com modelos tradicionais
- Implementar prÃ¡ticas de Infrastructure as Code (IaC)

## FundamentaÃ§Ã£o TeÃ³rica

A arquitetura serverless representa uma evoluÃ§Ã£o significativa no desenvolvimento de aplicaÃ§Ãµes distribuÃ­das. Segundo Roberts (2018), "serverless computing permite que desenvolvedores construam e executem aplicaÃ§Ãµes sem pensar em servidores" <sup>[1]</sup>.

### CaracterÃ­sticas da Arquitetura Serverless

Segundo Baldini et al. (2017), serverless computing possui trÃªs caracterÃ­sticas fundamentais <sup>[2]</sup>:

1. **Event-driven Execution**: FunÃ§Ãµes sÃ£o executadas em resposta a eventos especÃ­ficos
2. **Stateless Computation**: Cada invocaÃ§Ã£o Ã© independente, sem estado persistente
3. **Auto-scaling**: Escalamento automÃ¡tico baseado em demanda

**Vantagens:**
- **Custo**: Pagamento apenas por execuÃ§Ã£o real (pay-per-use)
- **Escalabilidade**: Escala automaticamente de zero a milhÃµes de requisiÃ§Ãµes
- **ManutenÃ§Ã£o**: Infraestrutura gerenciada pelo provedor cloud
- **Desenvolvimento**: Foco em lÃ³gica de negÃ³cio, nÃ£o em infraestrutura

**LimitaÃ§Ãµes:**
- **Cold Start**: LatÃªncia inicial quando funÃ§Ã£o estÃ¡ "fria"
- **Vendor Lock-in**: DependÃªncia de provedores especÃ­ficos
- **Tempo de ExecuÃ§Ã£o**: LimitaÃ§Ãµes de timeout (AWS Lambda: 15 minutos mÃ¡ximo)
- **Debugging**: Complexidade no rastreamento distribuÃ­do

### Function as a Service (FaaS)

O modelo FaaS representa o nÃºcleo do serverless. Na AWS Lambda, funÃ§Ãµes sÃ£o executadas em containers efÃªmeros que:
- Inicializam sob demanda
- Processam um Ãºnico evento por vez
- SÃ£o descartados apÃ³s perÃ­odo de inatividade
- Escalam horizontalmente de forma transparente

### LocalStack para Desenvolvimento Local

LocalStack Ã© um emulador completo de serviÃ§os AWS que permite desenvolvimento e testes locais sem custos de cloud. Segundo a documentaÃ§Ã£o oficial, "LocalStack fornece um ambiente de teste fÃ¡cil de usar para desenvolvimento de aplicaÃ§Ãµes cloud" <sup>[3]</sup>.

**ServiÃ§os Suportados:**
- AWS Lambda (execuÃ§Ã£o de funÃ§Ãµes)
- S3 (armazenamento de objetos)
- DynamoDB (banco NoSQL)
- SNS (notificaÃ§Ãµes pub/sub)
- API Gateway (gerenciamento de APIs)
- CloudFormation (infraestrutura como cÃ³digo)

## CenÃ¡rio do LaboratÃ³rio

Sistema de processamento de dados serverless implementando pipeline event-driven:

1. **Upload de arquivo CSV** â†’ S3 Bucket
2. **Trigger automÃ¡tico** â†’ Lambda Function
3. **Processamento** â†’ Parsing e validaÃ§Ã£o de dados
4. **PersistÃªncia** â†’ DynamoDB Table
5. **NotificaÃ§Ã£o** â†’ SNS Topic
6. **API REST** â†’ CriaÃ§Ã£o manual de registros

**Arquitetura Implementada:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   CSV File  â”‚â”€â”€â”€â”€â–¶â”‚  S3 Bucket   â”‚â”€â”€â”€â”€â–¶â”‚   Lambda    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚  Processor  â”‚
                                          â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                                                 â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚                            â”‚            â”‚
                    â–¼                            â–¼            â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚  API Gateway â”‚           â”‚   DynamoDB   â”‚  â”‚   SNS   â”‚
            â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚   Lambda     â”‚
            â”‚  API Handler â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## PrÃ©-requisitos

- Node.js 18+ e NPM
- Docker Desktop instalado e rodando
- VS Code ou editor similar
- AWS CLI (opcional, para testes avanÃ§ados)
- Conhecimento bÃ¡sico de JavaScript/Node.js

---

## **PASSO 1: ConfiguraÃ§Ã£o do Ambiente**

### 1.1 Instalar Ferramentas Globais

```bash
# Instalar Serverless Framework versÃ£o 3
# VersÃ£o 3 Ã© mais estÃ¡vel para desenvolvimento educacional
npm install -g serverless@3

# Verificar instalaÃ§Ã£o
serverless --version
# SaÃ­da esperada: Framework Core: 3.x.x

# Instalar AWS CLI Local (opcional, mas recomendado)
pip install awscli-local
```

### 1.2 Criar Estrutura do Projeto

```bash
# Criar diretÃ³rio raiz
mkdir lab04-serverless-localstack
cd lab04-serverless-localstack

# Criar estrutura de diretÃ³rios
mkdir -p data/input
mkdir -p src/handlers
mkdir -p src/utils
mkdir -p scripts
mkdir -p tests

# Inicializar projeto Node.js
npm init -y
```

### 1.3 Instalar DependÃªncias

```bash
# DependÃªncias principais
npm install aws-sdk uuid csv-parser

# DependÃªncias de desenvolvimento
npm install --save-dev \
  serverless@3 \
  serverless-localstack \
  serverless-offline \
  @types/node \
  @types/aws-lambda \
  eslint

# Configurar TypeScript (opcional)
npm install --save-dev typescript @types/node
```

### 1.4 Estrutura Final de DiretÃ³rios

```
lab04-serverless-localstack/
â”œâ”€â”€ package.json
â”œâ”€â”€ serverless.yml              # ConfiguraÃ§Ã£o Infrastructure as Code
â”œâ”€â”€ docker-compose.yml          # LocalStack container
â”œâ”€â”€ .env                        # VariÃ¡veis de ambiente
â”œâ”€â”€ .gitignore
â”œâ”€â”€ tsconfig.json               # ConfiguraÃ§Ã£o TypeScript (opcional)
â”œâ”€â”€ data/
â”‚   â””â”€â”€ input/
â”‚       â””â”€â”€ produtos.csv        # Dados de teste
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ handlers/
â”‚   â”‚   â”œâ”€â”€ dataProcessor.js    # Lambda: Processar CSV
â”‚   â”‚   â””â”€â”€ createRecord.js     # Lambda: API REST
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ dynamodb.js         # Helper DynamoDB
â”‚       â”œâ”€â”€ s3.js               # Helper S3
â”‚       â””â”€â”€ sns.js              # Helper SNS
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ test-pipeline.js        # Script de teste automatizado
â”‚   â””â”€â”€ setup.js                # Setup inicial
â””â”€â”€ tests/
    â”œâ”€â”€ test-event.json         # Evento S3 simulado
    â””â”€â”€ test-api.json           # RequisiÃ§Ã£o API simulada
```

---

## **PASSO 2: ConfiguraÃ§Ã£o do LocalStack**

### 2.1 Docker Compose Configuration (`docker-compose.yml`)

```yaml
version: '3.8'

services:
  localstack:
    container_name: localstack-serverless-lab
    image: localstack/localstack:latest
    ports:
      - "4566:4566"            # Gateway principal LocalStack
      - "4510-4559:4510-4559"  # Range para serviÃ§os externos
    
    environment:
      # ServiÃ§os AWS a serem emulados
      - SERVICES=lambda,dynamodb,s3,sns,iam,logs,cloudwatch,cloudformation,apigateway
      
      # ConfiguraÃ§Ãµes de debug
      - DEBUG=1
      - LS_LOG=INFO
      
      # ConfiguraÃ§Ãµes Lambda
      - LAMBDA_EXECUTOR=docker
      - LAMBDA_REMOTE_DOCKER=0
      - LAMBDA_DOCKER_NETWORK=localstack-network
      
      # PersistÃªncia desabilitada para desenvolvimento
      # Em produÃ§Ã£o, considere habilitar para manter dados
      - PERSISTENCE=0
      
      # ConfiguraÃ§Ãµes adicionais
      - DOCKER_HOST=unix:///var/run/docker.sock
    
    volumes:
      # Volume para persistÃªncia (se habilitado)
      - localstack-data:/var/lib/localstack
      # Socket do Docker para execuÃ§Ã£o de Lambda
      - "/var/run/docker.sock:/var/run/docker.sock"
    
    networks:
      - localstack-network
    
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:4566/_localstack/health"]
      interval: 10s
      timeout: 5s
      retries: 3
      start_period: 30s

volumes:
  localstack-data:
    driver: local

networks:
  localstack-network:
    driver: bridge
```

**ExplicaÃ§Ã£o dos Componentes:**

- **SERVICES**: Lista de serviÃ§os AWS emulados localmente
- **LAMBDA_EXECUTOR=docker**: Lambda executa em containers Docker isolados
- **PERSISTENCE=0**: Dados nÃ£o sÃ£o persistidos entre reinicializaÃ§Ãµes (ideal para desenvolvimento)
- **healthcheck**: Verifica se LocalStack estÃ¡ pronto para receber requisiÃ§Ãµes

### 2.2 Iniciar LocalStack

```bash
# Iniciar containers em background
docker-compose up -d

# Verificar status
docker-compose ps

# Aguardar LocalStack ficar pronto
echo "Aguardando LocalStack inicializar..."
sleep 30

# Verificar saÃºde do serviÃ§o
curl http://localhost:4566/_localstack/health
```

### 2.3 Verificar ServiÃ§os DisponÃ­veis

```bash
# Listar serviÃ§os rodando
curl http://localhost:4566/_localstack/health | json_pp

# SaÃ­da esperada:
# {
#   "services": {
#     "lambda": "running",
#     "dynamodb": "running",
#     "s3": "running",
#     "sns": "running",
#     ...
#   }
# }
```

---

## **PASSO 3: ConfiguraÃ§Ã£o do Serverless Framework**

### 3.1 Serverless Configuration (`serverless.yml`)

```yaml
service: data-processing-service

# VersÃ£o do Serverless Framework
frameworkVersion: '^3.38.0'

provider:
  name: aws
  runtime: nodejs18.x
  stage: ${opt:stage, 'local'}
  region: us-east-1
  
  # VariÃ¡veis de ambiente globais para todas as funÃ§Ãµes
  environment:
    TABLE_NAME: ${self:custom.tableName}
    BUCKET_NAME: ${self:custom.bucketName}
    TOPIC_ARN: 
      Ref: DataProcessingTopic
    AWS_ENDPOINT_URL: ${self:custom.localstack.endpoint}
  
  # PolÃ­ticas IAM para as funÃ§Ãµes Lambda
  iam:
    role:
      statements:
        # PermissÃµes DynamoDB
        - Effect: Allow
          Action:
            - dynamodb:PutItem
            - dynamodb:GetItem
            - dynamodb:Query
            - dynamodb:Scan
            - dynamodb:UpdateItem
            - dynamodb:DeleteItem
          Resource:
            Fn::GetAtt:
              - ProcessedDataTable
              - Arn
        
        # PermissÃµes S3
        - Effect: Allow
          Action:
            - s3:GetObject
            - s3:ListBucket
          Resource:
            - Fn::GetAtt:
                - DataProcessingBucket
                - Arn
            - Fn::Join:
                - ''
                - - Fn::GetAtt:
                      - DataProcessingBucket
                      - Arn
                  - '/*'
        
        # PermissÃµes SNS
        - Effect: Allow
          Action:
            - sns:Publish
          Resource:
            Ref: DataProcessingTopic
        
        # PermissÃµes CloudWatch Logs
        - Effect: Allow
          Action:
            - logs:CreateLogGroup
            - logs:CreateLogStream
            - logs:PutLogEvents
          Resource: '*'

# ConfiguraÃ§Ãµes customizadas
custom:
  # Nomes dos recursos
  tableName: ProcessedData
  bucketName: data-processing-bucket
  topicName: data-processing-notifications
  
  # ConfiguraÃ§Ã£o LocalStack
  localstack:
    stages:
      - local
    host: http://localhost
    edgePort: 4566
    autostart: false
    endpoint: http://localhost:4566
    lambda:
      mountCode: false
    docker:
      sudo: false

# Plugins necessÃ¡rios
plugins:
  - serverless-localstack
  - serverless-offline

# DefiniÃ§Ã£o das funÃ§Ãµes Lambda
functions:
  # FunÃ§Ã£o 1: Processar arquivos CSV do S3
  dataProcessor:
    handler: src/handlers/dataProcessor.handler
    name: DataProcessorFunction
    description: Processa arquivos CSV do S3 e salva no DynamoDB
    timeout: 60
    memorySize: 256
    environment:
      # Override de variÃ¡veis especÃ­ficas para LocalStack
      AWS_ACCESS_KEY_ID: test
      AWS_SECRET_ACCESS_KEY: test
    events:
      # Trigger: Evento S3 quando arquivo Ã© criado
      - s3:
          bucket: 
            Ref: DataProcessingBucket
          event: s3:ObjectCreated:*
          rules:
            - prefix: input/
            - suffix: .csv
          existing: true

  # FunÃ§Ã£o 2: API REST para criar registros
  createRecord:
    handler: src/handlers/createRecord.handler
    name: CreateRecordFunction
    description: API REST para criar registros no DynamoDB
    timeout: 10
    memorySize: 128
    environment:
      AWS_ACCESS_KEY_ID: test
      AWS_SECRET_ACCESS_KEY: test
    events:
      # Trigger: HTTP POST /records
      - http:
          path: records
          method: post
          cors: true

# Recursos AWS (Infrastructure as Code usando CloudFormation)
resources:
  Resources:
    # S3 Bucket para armazenar arquivos CSV
    DataProcessingBucket:
      Type: AWS::S3::Bucket
      Properties:
        BucketName: ${self:custom.bucketName}
        PublicAccessBlockConfiguration:
          BlockPublicAcls: true
          BlockPublicPolicy: true
          IgnorePublicAcls: true
          RestrictPublicBuckets: true
    
    # PermissÃ£o para S3 invocar Lambda
    DataProcessorLambdaPermissionS3:
      Type: AWS::Lambda::Permission
      Properties:
        FunctionName:
          Fn::GetAtt:
            - DataProcessorLambdaFunction
            - Arn
        Action: lambda:InvokeFunction
        Principal: s3.amazonaws.com
        SourceArn:
          Fn::GetAtt:
            - DataProcessingBucket
            - Arn
    
    # Tabela DynamoDB para armazenar dados processados
    ProcessedDataTable:
      Type: AWS::DynamoDB::Table
      Properties:
        TableName: ${self:custom.tableName}
        BillingMode: PAY_PER_REQUEST
        AttributeDefinitions:
          - AttributeName: id
            AttributeType: S
          - AttributeName: timestamp
            AttributeType: N
        KeySchema:
          - AttributeName: id
            KeyType: HASH
          - AttributeName: timestamp
            KeyType: RANGE
        StreamSpecification:
          StreamViewType: NEW_AND_OLD_IMAGES
        Tags:
          - Key: Environment
            Value: ${self:provider.stage}
          - Key: Service
            Value: ${self:service}
    
    # TÃ³pico SNS para notificaÃ§Ãµes
    DataProcessingTopic:
      Type: AWS::SNS::Topic
      Properties:
        TopicName: ${self:custom.topicName}
        DisplayName: Data Processing Notifications
        Tags:
          - Key: Environment
            Value: ${self:provider.stage}
  
  # Outputs (valores exportados para referÃªncia)
  Outputs:
    BucketName:
      Description: Nome do bucket S3
      Value:
        Ref: DataProcessingBucket
      Export:
        Name: ${self:service}-${self:provider.stage}-BucketName
    
    TableName:
      Description: Nome da tabela DynamoDB
      Value:
        Ref: ProcessedDataTable
      Export:
        Name: ${self:service}-${self:provider.stage}-TableName
    
    TopicArn:
      Description: ARN do tÃ³pico SNS
      Value:
        Ref: DataProcessingTopic
      Export:
        Name: ${self:service}-${self:provider.stage}-TopicArn
    
    FunctionArn:
      Description: ARN da funÃ§Ã£o Lambda principal
      Value:
        Fn::GetAtt:
          - DataProcessorLambdaFunction
          - Arn
      Export:
        Name: ${self:service}-${self:provider.stage}-FunctionArn
    
    ApiEndpoint:
      Description: URL do API Gateway
      Value:
        Fn::Sub: http://localhost:4566/restapis/${ApiGatewayRestApi}/local/_user_request_
```

**Conceitos Importantes:**

- **Infrastructure as Code (IaC)**: Toda infraestrutura definida em cÃ³digo versionÃ¡vel
- **Resources**: Recursos AWS definidos usando CloudFormation syntax
- **Outputs**: Valores exportados que podem ser referenciados por outros stacks
- **IAM Policies**: PrincÃ­pio de menor privilÃ©gio - apenas permissÃµes necessÃ¡rias

---

## **PASSO 4: ImplementaÃ§Ã£o dos Helpers**

### 4.1 DynamoDB Helper (`src/utils/dynamodb.js`)

```javascript
const AWS = require('aws-sdk');

/**
 * Helper para operaÃ§Ãµes com DynamoDB
 * 
 * Abstrai a complexidade das operaÃ§Ãµes com DynamoDB,
 * facilitando put, get, query e scan operations
 */

// ConfiguraÃ§Ã£o para LocalStack
const dynamoDbConfig = {
  endpoint: process.env.AWS_ENDPOINT_URL || 'http://localhost:4566',
  region: process.env.AWS_REGION || 'us-east-1',
  accessKeyId: process.env.AWS_ACCESS_KEY_ID || 'test',
  secretAccessKey: process.env.AWS_SECRET_ACCESS_KEY || 'test'
};

const dynamodb = new AWS.DynamoDB.DocumentClient(dynamoDbConfig);
const tableName = process.env.TABLE_NAME || 'ProcessedData';

/**
 * Inserir item no DynamoDB
 * @param {Object} item - Item a ser inserido
 * @returns {Promise<Object>} Resultado da operaÃ§Ã£o
 */
async function putItem(item) {
  const params = {
    TableName: tableName,
    Item: item
  };

  try {
    await dynamodb.put(params).promise();
    console.log(`âœ… Item inserido no DynamoDB: ${item.id}`);
    return { success: true, item };
  } catch (error) {
    console.error('âŒ Erro ao inserir item no DynamoDB:', error);
    throw error;
  }
}

/**
 * Buscar item por chave primÃ¡ria
 * @param {string} id - Partition key
 * @param {number} timestamp - Sort key
 * @returns {Promise<Object>} Item encontrado
 */
async function getItem(id, timestamp) {
  const params = {
    TableName: tableName,
    Key: { id, timestamp }
  };

  try {
    const result = await dynamodb.get(params).promise();
    return result.Item;
  } catch (error) {
    console.error('âŒ Erro ao buscar item:', error);
    throw error;
  }
}

/**
 * Query items por partition key
 * @param {string} id - Partition key
 * @returns {Promise<Array>} Lista de items
 */
async function queryByIdAsync(id) {
  const params = {
    TableName: tableName,
    KeyConditionExpression: 'id = :id',
    ExpressionAttributeValues: {
      ':id': id
    }
  };

  try {
    const result = await dynamodb.query(params).promise();
    return result.Items;
  } catch (error) {
    console.error('âŒ Erro ao fazer query:', error);
    throw error;
  }
}

/**
 * Scan completo da tabela (use com cuidado em produÃ§Ã£o!)
 * @param {number} limit - Limite de items a retornar
 * @returns {Promise<Array>} Lista de todos os items
 */
async function scanTable(limit = 100) {
  const params = {
    TableName: tableName,
    Limit: limit
  };

  try {
    const result = await dynamodb.scan(params).promise();
    console.log(`ğŸ“Š Scan retornou ${result.Items.length} items`);
    return result.Items;
  } catch (error) {
    console.error('âŒ Erro ao fazer scan:', error);
    throw error;
  }
}

/**
 * Atualizar item existente
 * @param {string} id - Partition key
 * @param {number} timestamp - Sort key
 * @param {Object} updates - Campos a atualizar
 * @returns {Promise<Object>} Item atualizado
 */
async function updateItem(id, timestamp, updates) {
  // Construir expressÃ£o de update dinamicamente
  const updateExpressionParts = [];
  const expressionAttributeNames = {};
  const expressionAttributeValues = {};

  Object.keys(updates).forEach((key, index) => {
    const placeholder = `#attr${index}`;
    const valuePlaceholder = `:val${index}`;
    
    updateExpressionParts.push(`${placeholder} = ${valuePlaceholder}`);
    expressionAttributeNames[placeholder] = key;
    expressionAttributeValues[valuePlaceholder] = updates[key];
  });

  const params = {
    TableName: tableName,
    Key: { id, timestamp },
    UpdateExpression: `SET ${updateExpressionParts.join(', ')}`,
    ExpressionAttributeNames: expressionAttributeNames,
    ExpressionAttributeValues: expressionAttributeValues,
    ReturnValues: 'ALL_NEW'
  };

  try {
    const result = await dynamodb.update(params).promise();
    console.log(`âœï¸ Item atualizado: ${id}`);
    return result.Attributes;
  } catch (error) {
    console.error('âŒ Erro ao atualizar item:', error);
    throw error;
  }
}

/**
 * Deletar item
 * @param {string} id - Partition key
 * @param {number} timestamp - Sort key
 * @returns {Promise<Object>} Resultado da operaÃ§Ã£o
 */
async function deleteItem(id, timestamp) {
  const params = {
    TableName: tableName,
    Key: { id, timestamp }
  };

  try {
    await dynamodb.delete(params).promise();
    console.log(`ğŸ—‘ï¸ Item deletado: ${id}`);
    return { success: true };
  } catch (error) {
    console.error('âŒ Erro ao deletar item:', error);
    throw error;
  }
}

module.exports = {
  putItem,
  getItem,
  queryByIdAsync,
  scanTable,
  updateItem,
  deleteItem
};
```

### 4.2 S3 Helper (`src/utils/s3.js`)

```javascript
const AWS = require('aws-sdk');

/**
 * Helper para operaÃ§Ãµes com S3
 * 
 * Facilita operaÃ§Ãµes de leitura e escrita em buckets S3
 */

const s3Config = {
  endpoint: process.env.AWS_ENDPOINT_URL || 'http://localhost:4566',
  region: process.env.AWS_REGION || 'us-east-1',
  accessKeyId: process.env.AWS_ACCESS_KEY_ID || 'test',
  secretAccessKey: process.env.AWS_SECRET_ACCESS_KEY || 'test',
  s3ForcePathStyle: true // NecessÃ¡rio para LocalStack
};

const s3 = new AWS.S3(s3Config);

/**
 * Ler conteÃºdo de arquivo do S3
 * @param {string} bucket - Nome do bucket
 * @param {string} key - Chave do objeto
 * @returns {Promise<string>} ConteÃºdo do arquivo
 */
async function getObject(bucket, key) {
  const params = {
    Bucket: bucket,
    Key: key
  };

  try {
    console.log(`ğŸ“¥ Lendo arquivo: s3://${bucket}/${key}`);
    const result = await s3.getObject(params).promise();
    return result.Body.toString('utf-8');
  } catch (error) {
    console.error('âŒ Erro ao ler objeto do S3:', error);
    throw error;
  }
}

/**
 * Upload de arquivo para S3
 * @param {string} bucket - Nome do bucket
 * @param {string} key - Chave do objeto
 * @param {string|Buffer} body - ConteÃºdo do arquivo
 * @param {string} contentType - MIME type
 * @returns {Promise<Object>} Resultado do upload
 */
async function putObject(bucket, key, body, contentType = 'text/plain') {
  const params = {
    Bucket: bucket,
    Key: key,
    Body: body,
    ContentType: contentType
  };

  try {
    console.log(`ğŸ“¤ Fazendo upload: s3://${bucket}/${key}`);
    const result = await s3.putObject(params).promise();
    console.log(`âœ… Upload concluÃ­do: ${key}`);
    return result;
  } catch (error) {
    console.error('âŒ Erro ao fazer upload para S3:', error);
    throw error;
  }
}

/**
 * Listar objetos em um bucket
 * @param {string} bucket - Nome do bucket
 * @param {string} prefix - Prefixo para filtrar objetos
 * @returns {Promise<Array>} Lista de objetos
 */
async function listObjects(bucket, prefix = '') {
  const params = {
    Bucket: bucket,
    Prefix: prefix
  };

  try {
    const result = await s3.listObjectsV2(params).promise();
    console.log(`ğŸ“‹ Encontrados ${result.Contents.length} objetos`);
    return result.Contents;
  } catch (error) {
    console.error('âŒ Erro ao listar objetos:', error);
    throw error;
  }
}

/**
 * Deletar objeto do S3
 * @param {string} bucket - Nome do bucket
 * @param {string} key - Chave do objeto
 * @returns {Promise<Object>} Resultado da operaÃ§Ã£o
 */
async function deleteObject(bucket, key) {
  const params = {
    Bucket: bucket,
    Key: key
  };

  try {
    await s3.deleteObject(params).promise();
    console.log(`ğŸ—‘ï¸ Objeto deletado: ${key}`);
    return { success: true };
  } catch (error) {
    console.error('âŒ Erro ao deletar objeto:', error);
    throw error;
  }
}

/**
 * Verificar se bucket existe
 * @param {string} bucket - Nome do bucket
 * @returns {Promise<boolean>} True se existe
 */
async function bucketExists(bucket) {
  try {
    await s3.headBucket({ Bucket: bucket }).promise();
    return true;
  } catch (error) {
    if (error.code === 'NotFound') {
      return false;
    }
    throw error;
  }
}

module.exports = {
  getObject,
  putObject,
  listObjects,
  deleteObject,
  bucketExists
};
```

### 4.3 SNS Helper (`src/utils/sns.js`)

```javascript
const AWS = require('aws-sdk');

/**
 * Helper para notificaÃ§Ãµes SNS
 * 
 * Simplifica publicaÃ§Ã£o de mensagens em tÃ³picos SNS
 */

const snsConfig = {
  endpoint: process.env.AWS_ENDPOINT_URL || 'http://localhost:4566',
  region: process.env.AWS_REGION || 'us-east-1',
  accessKeyId: process.env.AWS_ACCESS_KEY_ID || 'test',
  secretAccessKey: process.env.AWS_SECRET_ACCESS_KEY || 'test'
};

const sns = new AWS.SNS(snsConfig);

/**
 * Publicar mensagem em tÃ³pico SNS
 * @param {string} topicArn - ARN do tÃ³pico
 * @param {string} message - Mensagem a publicar
 * @param {string} subject - Assunto da mensagem
 * @param {Object} attributes - Atributos adicionais
 * @returns {Promise<Object>} Resultado da publicaÃ§Ã£o
 */
async function publishMessage(topicArn, message, subject = 'Notification', attributes = {}) {
  const params = {
    TopicArn: topicArn,
    Message: typeof message === 'object' ? JSON.stringify(message) : message,
    Subject: subject,
    MessageAttributes: {}
  };

  // Adicionar atributos customizados
  Object.keys(attributes).forEach(key => {
    params.MessageAttributes[key] = {
      DataType: 'String',
      StringValue: String(attributes[key])
    };
  });

  try {
    console.log(`ğŸ“¢ Publicando mensagem SNS: ${subject}`);
    const result = await sns.publish(params).promise();
    console.log(`âœ… Mensagem publicada. MessageId: ${result.MessageId}`);
    return result;
  } catch (error) {
    console.error('âŒ Erro ao publicar mensagem SNS:', error);
    throw error;
  }
}

/**
 * Criar tÃ³pico SNS
 * @param {string} topicName - Nome do tÃ³pico
 * @returns {Promise<string>} ARN do tÃ³pico criado
 */
async function createTopic(topicName) {
  const params = {
    Name: topicName
  };

  try {
    const result = await sns.createTopic(params).promise();
    console.log(`âœ… TÃ³pico criado: ${result.TopicArn}`);
    return result.TopicArn;
  } catch (error) {
    console.error('âŒ Erro ao criar tÃ³pico:', error);
    throw error;
  }
}

/**
 * Inscrever endpoint em tÃ³pico
 * @param {string} topicArn - ARN do tÃ³pico
 * @param {string} protocol - Protocolo (email, sms, http, etc)
 * @param {string} endpoint - Endpoint a ser inscrito
 * @returns {Promise<Object>} Resultado da inscriÃ§Ã£o
 */
async function subscribe(topicArn, protocol, endpoint) {
  const params = {
    TopicArn: topicArn,
    Protocol: protocol,
    Endpoint: endpoint
  };

  try {
    const result = await sns.subscribe(params).promise();
    console.log(`âœ… InscriÃ§Ã£o criada. SubscriptionArn: ${result.SubscriptionArn}`);
    return result;
  } catch (error) {
    console.error('âŒ Erro ao criar inscriÃ§Ã£o:', error);
    throw error;
  }
}

/**
 * Listar tÃ³picos SNS
 * @returns {Promise<Array>} Lista de tÃ³picos
 */
async function listTopics() {
  try {
    const result = await sns.listTopics().promise();
    return result.Topics;
  } catch (error) {
    console.error('âŒ Erro ao listar tÃ³picos:', error);
    throw error;
  }
}

module.exports = {
  publishMessage,
  createTopic,
  subscribe,
  listTopics
};
```

---

## **PASSO 5: ImplementaÃ§Ã£o das FunÃ§Ãµes Lambda**

### 5.1 Lambda Data Processor (`src/handlers/dataProcessor.js`)

```javascript
const { getObject } = require('../utils/s3');
const { putItem } = require('../utils/dynamodb');
const { publishMessage } = require('../utils/sns');
const { v4: uuidv4 } = require('uuid');

/**
 * Lambda Handler: Data Processor
 * 
 * FunÃ§Ã£o principal que processa arquivos CSV do S3:
 * 1. Recebe evento de criaÃ§Ã£o de arquivo no S3
 * 2. LÃª e parseia o arquivo CSV
 * 3. Valida e transforma os dados
 * 4. Salva cada registro no DynamoDB
 * 5. Publica notificaÃ§Ã£o SNS ao concluir
 * 
 * @param {Object} event - Evento S3 trigger
 * @param {Object} context - Contexto da execuÃ§Ã£o Lambda
 * @returns {Promise<Object>} Resultado do processamento
 */
exports.handler = async (event, context) => {
  console.log('ğŸš€ Lambda Data Processor iniciada');
  console.log('ğŸ“‹ Evento recebido:', JSON.stringify(event, null, 2));

  try {
    // Extrair informaÃ§Ãµes do evento S3
    const record = event.Records[0];
    const bucket = record.s3.bucket.name;
    const key = decodeURIComponent(record.s3.object.key.replace(/\+/g, ' '));
    
    console.log(`ğŸ“ Processando arquivo: s3://${bucket}/${key}`);

    // 1. Ler arquivo CSV do S3
    const csvContent = await getObject(bucket, key);
    console.log(`ğŸ“„ ConteÃºdo do arquivo lido (${csvContent.length} bytes)`);

    // 2. Parsear CSV manualmente (sem dependÃªncia externa de csv-parser)
    const lines = csvContent.trim().split('\n');
    const headers = lines[0].split(',').map(h => h.trim());
    
    console.log(`ğŸ“Š Headers encontrados: ${headers.join(', ')}`);
    console.log(`ğŸ“ˆ Total de linhas (incluindo header): ${lines.length}`);

    const records = [];
    let processedCount = 0;
    let errorCount = 0;

    // 3. Processar cada linha do CSV
    for (let i = 1; i < lines.length; i++) {
      const line = lines[i].trim();
      
      // Pular linhas vazias
      if (!line) continue;

      try {
        const values = line.split(',').map(v => v.trim());
        
        // Criar objeto a partir dos headers e values
        const record = {};
        headers.forEach((header, index) => {
          record[header] = values[index];
        });

        // Validar registro
        if (!record.id || !record.nome) {
          console.warn(`âš ï¸ Linha ${i + 1}: Dados incompletos, pulando...`);
          errorCount++;
          continue;
        }

        // 4. Enriquecer dados
        const enrichedRecord = {
          id: String(record.id),
          timestamp: Date.now(),
          nome: record.nome,
          categoria: record.categoria || 'Sem categoria',
          preco: parseFloat(record.preco) || 0,
          estoque: parseInt(record.estoque) || 0,
          source_file: key,
          processed_at: new Date().toISOString(),
          processor_version: '1.0.0'
        };

        // 5. Salvar no DynamoDB
        await putItem(enrichedRecord);
        records.push(enrichedRecord);
        processedCount++;
        
        console.log(`âœ… Linha ${i + 1} processada: ${record.nome}`);

      } catch (error) {
        console.error(`âŒ Erro ao processar linha ${i + 1}:`, error.message);
        errorCount++;
      }
    }

    // 6. Publicar notificaÃ§Ã£o SNS
    const topicArn = process.env.TOPIC_ARN;
    const notification = {
      event_type: 'DATA_PROCESSING_COMPLETED',
      file: key,
      bucket: bucket,
      records_processed: processedCount,
      records_failed: errorCount,
      total_records: lines.length - 1,
      processed_at: new Date().toISOString(),
      lambda_request_id: context.requestId
    };

    if (topicArn) {
      await publishMessage(
        topicArn,
        notification,
        'Data Processing Completed',
        {
          event_type: 'processing_completed',
          file_name: key,
          records_count: String(processedCount)
        }
      );
    }

    // 7. Retornar resultado
    const result = {
      statusCode: 200,
      body: JSON.stringify({
        message: 'Processamento concluÃ­do com sucesso',
        file: key,
        records_processed: processedCount,
        records_failed: errorCount,
        total_records: lines.length - 1,
        success_rate: ((processedCount / (lines.length - 1)) * 100).toFixed(2) + '%'
      })
    };

    console.log('âœ… Processamento concluÃ­do:', result.body);
    return result;

  } catch (error) {
    console.error('âŒ Erro fatal no processamento:', error);
    
    // Publicar notificaÃ§Ã£o de erro
    try {
      const topicArn = process.env.TOPIC_ARN;
      if (topicArn) {
        await publishMessage(
          topicArn,
          {
            event_type: 'DATA_PROCESSING_FAILED',
            error: error.message,
            stack: error.stack,
            processed_at: new Date().toISOString()
          },
          'Data Processing Failed'
        );
      }
    } catch (notifyError) {
      console.error('âŒ Erro ao enviar notificaÃ§Ã£o de falha:', notifyError);
    }

    return {
      statusCode: 500,
      body: JSON.stringify({
        message: 'Erro no processamento',
        error: error.message
      })
    };
  }
};
```

### 5.2 Lambda API Handler (`src/handlers/createRecord.js`)

```javascript
const { putItem } = require('../utils/dynamodb');
const { publishMessage } = require('../utils/sns');
const { v4: uuidv4 } = require('uuid');

/**
 * Lambda Handler: Create Record API
 * 
 * Endpoint REST para criar registros diretamente no DynamoDB
 * via requisiÃ§Ã£o HTTP POST
 * 
 * Endpoint: POST /records
 * Body: JSON com dados do registro
 * 
 * @param {Object} event - Evento API Gateway
 * @param {Object} context - Contexto da execuÃ§Ã£o Lambda
 * @returns {Promise<Object>} Resposta HTTP
 */
exports.handler = async (event, context) => {
  console.log('ğŸŒ Lambda API Handler iniciada');
  console.log('ğŸ“‹ Evento recebido:', JSON.stringify(event, null, 2));

  // Headers CORS para permitir requisiÃ§Ãµes cross-origin
  const headers = {
    'Content-Type': 'application/json',
    'Access-Control-Allow-Origin': '*',
    'Access-Control-Allow-Methods': 'POST, OPTIONS',
    'Access-Control-Allow-Headers': 'Content-Type'
  };

  // Tratar preflight request (OPTIONS)
  if (event.httpMethod === 'OPTIONS') {
    return {
      statusCode: 200,
      headers,
      body: JSON.stringify({ message: 'CORS preflight successful' })
    };
  }

  try {
    // 1. Validar mÃ©todo HTTP
    if (event.httpMethod !== 'POST') {
      return {
        statusCode: 405,
        headers,
        body: JSON.stringify({
          error: 'Method Not Allowed',
          message: 'Apenas POST Ã© permitido'
        })
      };
    }

    // 2. Parsear body da requisiÃ§Ã£o
    let body;
    try {
      body = typeof event.body === 'string' 
        ? JSON.parse(event.body) 
        : event.body;
    } catch (parseError) {
      return {
        statusCode: 400,
        headers,
        body: JSON.stringify({
          error: 'Invalid JSON',
          message: 'Body da requisiÃ§Ã£o nÃ£o Ã© um JSON vÃ¡lido'
        })
      };
    }

    // 3. Validar campos obrigatÃ³rios
    if (!body.nome) {
      return {
        statusCode: 400,
        headers,
        body: JSON.stringify({
          error: 'Validation Error',
          message: 'Campo "nome" Ã© obrigatÃ³rio'
        })
      };
    }

    // 4. Criar registro enriquecido
    const itemId = body.id || uuidv4();
    const timestamp = Date.now();

    const item = {
      id: itemId,
      timestamp: timestamp,
      nome: body.nome,
      categoria: body.categoria || 'API',
      preco: parseFloat(body.preco) || 0,
      estoque: parseInt(body.estoque) || 0,
      source: 'API',
      created_at: new Date().toISOString(),
      created_by: event.requestContext?.identity?.sourceIp || 'unknown',
      request_id: context.requestId
    };

    console.log('ğŸ“ Criando registro:', JSON.stringify(item));

    // 5. Salvar no DynamoDB
    await putItem(item);

    // 6. Publicar notificaÃ§Ã£o SNS
    const topicArn = process.env.TOPIC_ARN;
    if (topicArn) {
      await publishMessage(
        topicArn,
        {
          event_type: 'RECORD_CREATED_VIA_API',
          record_id: itemId,
          record_name: body.nome,
          created_at: item.created_at
        },
        'New Record Created via API',
        {
          event_type: 'api_creation',
          record_id: itemId
        }
      );
    }

    // 7. Retornar resposta de sucesso
    return {
      statusCode: 201,
      headers,
      body: JSON.stringify({
        message: 'Registro criado com sucesso',
        id: itemId,
        timestamp: timestamp,
        data: item
      })
    };

  } catch (error) {
    console.error('âŒ Erro ao criar registro:', error);
    
    return {
      statusCode: 500,
      headers,
      body: JSON.stringify({
        error: 'Internal Server Error',
        message: error.message
      })
    };
  }
};
```

---

## **PASSO 6: Dados de Teste e Scripts**

### 6.1 Arquivo CSV de Teste (`data/input/produtos.csv`)

```csv
id,nome,categoria,preco,estoque
1,Notebook Dell XPS 15,InformÃ¡tica,8500.00,15
2,Mouse Logitech MX Master,PerifÃ©ricos,450.00,50
3,Teclado MecÃ¢nico Keychron,PerifÃ©ricos,890.00,30
4,Monitor LG UltraWide 34",Monitores,2800.00,20
5,Webcam Logitech C920,AcessÃ³rios,650.00,25
6,Headset HyperX Cloud,Ãudio,780.00,40
7,SSD Samsung 1TB,Armazenamento,580.00,60
8,HD Externo Seagate 2TB,Armazenamento,420.00,35
9,Cadeira Gamer ThunderX3,MÃ³veis,1200.00,12
10,Mesa Gamer Pro,MÃ³veis,1800.00,8
```

### 6.2 Evento S3 Simulado (`tests/test-event.json`)

```json
{
  "Records": [
    {
      "eventVersion": "2.1",
      "eventSource": "aws:s3",
      "awsRegion": "us-east-1",
      "eventTime": "2024-01-15T12:00:00.000Z",
      "eventName": "ObjectCreated:Put",
      "s3": {
        "s3SchemaVersion": "1.0",
        "configurationId": "data-processor-trigger",
        "bucket": {
          "name": "data-processing-bucket",
          "arn": "arn:aws:s3:::data-processing-bucket"
        },
        "object": {
          "key": "input/produtos.csv",
          "size": 1024,
          "eTag": "d41d8cd98f00b204e9800998ecf8427e"
        }
      }
    }
  ]
}
```

### 6.3 RequisiÃ§Ã£o API Simulada (`tests/test-api.json`)

```json
{
  "httpMethod": "POST",
  "path": "/records",
  "headers": {
    "Content-Type": "application/json"
  },
  "body": "{\"nome\":\"Produto de Teste API\",\"categoria\":\"Testes\",\"preco\":99.99,\"estoque\":100}",
  "requestContext": {
    "identity": {
      "sourceIp": "127.0.0.1"
    }
  }
}
```

### 6.4 Script de Teste Automatizado (`scripts/test-pipeline.js`)

```javascript
#!/usr/bin/env node

const AWS = require('aws-sdk');
const fs = require('fs');
const path = require('path');

/**
 * Script de Teste Automatizado do Pipeline
 * 
 * Testa todo o fluxo serverless:
 * 1. Upload de CSV para S3
 * 2. Trigger automÃ¡tico da Lambda
 * 3. VerificaÃ§Ã£o de dados no DynamoDB
 * 4. Teste de API REST
 */

// ConfiguraÃ§Ã£o AWS LocalStack
const awsConfig = {
  endpoint: 'http://localhost:4566',
  region: 'us-east-1',
  accessKeyId: 'test',
  secretAccessKey: 'test',
  s3ForcePathStyle: true
};

const s3 = new AWS.S3(awsConfig);
const dynamodb = new AWS.DynamoDB.DocumentClient(awsConfig);
const lambda = new AWS.Lambda(awsConfig);

const BUCKET_NAME = 'data-processing-bucket';
const TABLE_NAME = 'ProcessedData';
const TEST_FILE = path.join(__dirname, '../data/input/produtos.csv');

// Cores para output no terminal
const colors = {
  reset: '\x1b[0m',
  green: '\x1b[32m',
  red: '\x1b[31m',
  yellow: '\x1b[33m',
  blue: '\x1b[34m',
  magenta: '\x1b[35m'
};

function log(message, color = colors.reset) {
  console.log(`${color}${message}${colors.reset}`);
}

function success(message) {
  log(`âœ… ${message}`, colors.green);
}

function error(message) {
  log(`âŒ ${message}`, colors.red);
}

function info(message) {
  log(`â„¹ï¸  ${message}`, colors.blue);
}

function warning(message) {
  log(`âš ï¸  ${message}`, colors.yellow);
}

async function sleep(ms) {
  return new Promise(resolve => setTimeout(resolve, ms));
}

/**
 * Verificar se LocalStack estÃ¡ rodando
 */
async function checkLocalStack() {
  info('Verificando se LocalStack estÃ¡ ativo...');
  try {
    await s3.listBuckets().promise();
    success('LocalStack estÃ¡ ativo e respondendo');
    return true;
  } catch (err) {
    error('LocalStack nÃ£o estÃ¡ respondendo. Verifique se estÃ¡ rodando com: docker-compose ps');
    return false;
  }
}

/**
 * Verificar se bucket existe
 */
async function checkBucket() {
  info(`Verificando bucket ${BUCKET_NAME}...`);
  try {
    await s3.headBucket({ Bucket: BUCKET_NAME }).promise();
    success(`Bucket ${BUCKET_NAME} existe`);
    return true;
  } catch (err) {
    error(`Bucket ${BUCKET_NAME} nÃ£o existe. Execute: serverless deploy --stage local`);
    return false;
  }
}

/**
 * Verificar se tabela DynamoDB existe
 */
async function checkTable() {
  info(`Verificando tabela ${TABLE_NAME}...`);
  try {
    const params = {
      TableName: TABLE_NAME,
      Limit: 1
    };
    await dynamodb.scan(params).promise();
    success(`Tabela ${TABLE_NAME} existe e estÃ¡ acessÃ­vel`);
    return true;
  } catch (err) {
    error(`Tabela ${TABLE_NAME} nÃ£o estÃ¡ acessÃ­vel: ${err.message}`);
    return false;
  }
}

/**
 * Upload de arquivo CSV para S3
 */
async function uploadTestFile() {
  info('Fazendo upload do arquivo de teste...');
  
  if (!fs.existsSync(TEST_FILE)) {
    error(`Arquivo de teste nÃ£o encontrado: ${TEST_FILE}`);
    return false;
  }

  const fileContent = fs.readFileSync(TEST_FILE);
  const params = {
    Bucket: BUCKET_NAME,
    Key: 'input/produtos.csv',
    Body: fileContent,
    ContentType: 'text/csv'
  };

  try {
    await s3.putObject(params).promise();
    success('Arquivo uploaded com sucesso para s3://data-processing-bucket/input/produtos.csv');
    return true;
  } catch (err) {
    error(`Erro no upload: ${err.message}`);
    return false;
  }
}

/**
 * Aguardar Lambda processar (polling)
 */
async function waitForProcessing(maxAttempts = 10, interval = 2000) {
  info('Aguardando Lambda processar dados...');
  
  for (let i = 0; i < maxAttempts; i++) {
    try {
      const params = {
        TableName: TABLE_NAME,
        Limit: 1
      };
      
      const result = await dynamodb.scan(params).promise();
      
      if (result.Items && result.Items.length > 0) {
        success(`Dados processados encontrados no DynamoDB!`);
        return true;
      }
      
      warning(`Tentativa ${i + 1}/${maxAttempts}: Aguardando processamento...`);
      await sleep(interval);
    } catch (err) {
      warning(`Erro ao verificar DynamoDB: ${err.message}`);
    }
  }
  
  error('Timeout: Lambda nÃ£o processou dados no tempo esperado');
  return false;
}

/**
 * Verificar dados no DynamoDB
 */
async function verifyData() {
  info('Verificando dados processados no DynamoDB...');
  
  try {
    const params = {
      TableName: TABLE_NAME,
      Limit: 100
    };
    
    const result = await dynamodb.scan(params).promise();
    const items = result.Items || [];
    
    success(`Total de registros no DynamoDB: ${items.length}`);
    
    if (items.length > 0) {
      info('\nExemplo de registro processado:');
      console.log(JSON.stringify(items[0], null, 2));
      
      // Validar campos esperados
      const requiredFields = ['id', 'timestamp', 'nome', 'preco', 'source_file'];
      const firstItem = items[0];
      const missingFields = requiredFields.filter(field => !(field in firstItem));
      
      if (missingFields.length === 0) {
        success('Todos os campos esperados estÃ£o presentes');
      } else {
        warning(`Campos faltando: ${missingFields.join(', ')}`);
      }
      
      return true;
    } else {
      warning('Nenhum registro encontrado no DynamoDB');
      return false;
    }
  } catch (err) {
    error(`Erro ao verificar dados: ${err.message}`);
    return false;
  }
}

/**
 * Testar API REST
 */
async function testApi() {
  info('Testando API REST para criar registro...');
  
  try {
    const params = {
      FunctionName: 'CreateRecordFunction',
      InvocationType: 'RequestResponse',
      Payload: JSON.stringify({
        httpMethod: 'POST',
        body: JSON.stringify({
          nome: 'Produto Teste API',
          categoria: 'Teste Automatizado',
          preco: 199.99,
          estoque: 50
        }),
        requestContext: {
          identity: {
            sourceIp: '127.0.0.1'
          }
        }
      })
    };
    
    const result = await lambda.invoke(params).promise();
    const response = JSON.parse(result.Payload);
    
    if (response.statusCode === 201) {
      success('API REST funcionando corretamente');
      const body = JSON.parse(response.body);
      info(`Registro criado com ID: ${body.id}`);
      return true;
    } else {
      error(`API retornou status ${response.statusCode}`);
      console.log(response.body);
      return false;
    }
  } catch (err) {
    error(`Erro ao testar API: ${err.message}`);
    return false;
  }
}

/**
 * Limpar dados de teste
 */
async function cleanup() {
  info('Limpando dados de teste (opcional)...');
  warning('Para limpar completamente, execute: serverless remove --stage local');
}

/**
 * Main
 */
async function main() {
  console.log('\n' + '='.repeat(60));
  log('ğŸ§ª TESTE AUTOMATIZADO DO PIPELINE SERVERLESS', colors.magenta);
  console.log('='.repeat(60) + '\n');

  let allPassed = true;

  // Passo 1: Verificar LocalStack
  if (!await checkLocalStack()) {
    error('\nâŒ Falha crÃ­tica: LocalStack nÃ£o estÃ¡ disponÃ­vel');
    process.exit(1);
  }

  // Passo 2: Verificar recursos
  if (!await checkBucket() || !await checkTable()) {
    error('\nâŒ Recursos nÃ£o estÃ£o disponÃ­veis. Execute deploy primeiro.');
    process.exit(1);
  }

  // Passo 3: Upload de arquivo
  if (!await uploadTestFile()) {
    allPassed = false;
  }

  // Passo 4: Aguardar processamento
  await sleep(3000); // Aguardar um pouco antes de comeÃ§ar polling
  if (!await waitForProcessing()) {
    allPassed = false;
  }

  // Passo 5: Verificar dados
  if (!await verifyData()) {
    allPassed = false;
  }

  // Passo 6: Testar API
  await sleep(2000);
  if (!await testApi()) {
    allPassed = false;
  }

  // Passo 7: Cleanup
  await cleanup();

  // Resultado final
  console.log('\n' + '='.repeat(60));
  if (allPassed) {
    log('ğŸ‰ TODOS OS TESTES PASSARAM COM SUCESSO!', colors.green);
  } else {
    log('âš ï¸  ALGUNS TESTES FALHARAM', colors.yellow);
  }
  console.log('='.repeat(60) + '\n');
}

// Executar
main().catch(err => {
  error(`Erro fatal: ${err.message}`);
  console.error(err);
  process.exit(1);
});
```

### 6.5 Script de Setup Inicial (`scripts/setup.js`)

```javascript
#!/usr/bin/env node

const { execSync } = require('child_process');
const fs = require('fs');
const path = require('path');

/**
 * Script de Setup Inicial do Projeto
 * 
 * Automatiza configuraÃ§Ã£o inicial:
 * 1. Verifica dependÃªncias instaladas
 * 2. Inicia LocalStack
 * 3. Faz deploy do Serverless
 * 4. Executa teste bÃ¡sico
 */

function execute(command, options = {}) {
  console.log(`\nğŸ”§ Executando: ${command}`);
  try {
    execSync(command, { 
      stdio: 'inherit',
      ...options 
    });
    console.log('âœ… Comando executado com sucesso\n');
    return true;
  } catch (error) {
    console.error(`âŒ Erro ao executar comando: ${error.message}\n`);
    return false;
  }
}

function checkFile(filePath) {
  return fs.existsSync(filePath);
}

console.log('ğŸš€ Setup do Projeto Serverless LocalStack\n');
console.log('='.repeat(60) + '\n');

// 1. Verificar se estamos no diretÃ³rio correto
if (!checkFile('package.json')) {
  console.error('âŒ Erro: package.json nÃ£o encontrado. Execute este script do diretÃ³rio raiz do projeto.');
  process.exit(1);
}

// 2. Instalar dependÃªncias Node.js
console.log('ğŸ“¦ Passo 1: Instalando dependÃªncias Node.js...');
if (!execute('npm install')) {
  console.error('âŒ Falha ao instalar dependÃªncias');
  process.exit(1);
}

// 3. Verificar se Docker estÃ¡ rodando
console.log('ğŸ³ Passo 2: Verificando Docker...');
if (!execute('docker ps', { stdio: 'pipe' })) {
  console.error('âŒ Docker nÃ£o estÃ¡ rodando. Inicie o Docker Desktop e tente novamente.');
  process.exit(1);
}

// 4. Iniciar LocalStack
console.log('ğŸŒ Passo 3: Iniciando LocalStack...');
if (!execute('docker-compose up -d')) {
  console.error('âŒ Falha ao iniciar LocalStack');
  process.exit(1);
}

// 5. Aguardar LocalStack ficar pronto
console.log('â³ Aguardando LocalStack inicializar (30 segundos)...');
setTimeout(() => {}, 30000); // Aguardar sincronicamente
execSync('sleep 30', { stdio: 'inherit' });

// 6. Deploy do Serverless
console.log('â˜ï¸  Passo 4: Fazendo deploy do Serverless Framework...');
if (!execute('serverless deploy --stage local --verbose')) {
  console.error('âŒ Falha no deploy');
  process.exit(1);
}

// 7. Executar teste bÃ¡sico
console.log('ğŸ§ª Passo 5: Executando teste bÃ¡sico...');
if (checkFile('scripts/test-pipeline.js')) {
  execute('node scripts/test-pipeline.js');
}

console.log('\n' + '='.repeat(60));
console.log('âœ… Setup concluÃ­do com sucesso!');
console.log('='.repeat(60));
console.log('\nPrÃ³ximos passos:');
console.log('  1. Testar pipeline: node scripts/test-pipeline.js');
console.log('  2. Ver logs: serverless logs -f dataProcessor --stage local -t');
console.log('  3. Ver dados: aws --endpoint-url=http://localhost:4566 dynamodb scan --table-name ProcessedData');
console.log('  4. Remover tudo: serverless remove --stage local\n');
```

---

## **PASSO 7: ConfiguraÃ§Ãµes Adicionais**

### 7.1 Package.json

```json
{
  "name": "lab04-serverless-localstack",
  "version": "1.0.0",
  "description": "Pipeline de processamento de dados serverless com LocalStack",
  "main": "src/handlers/dataProcessor.js",
  "scripts": {
    "setup": "node scripts/setup.js",
    "test": "node scripts/test-pipeline.js",
    "deploy": "serverless deploy --stage local --verbose",
    "deploy:function": "serverless deploy function -f dataProcessor --stage local",
    "remove": "serverless remove --stage local",
    "logs": "serverless logs -f dataProcessor --stage local",
    "logs:tail": "serverless logs -f dataProcessor --stage local -t",
    "invoke": "serverless invoke -f dataProcessor --stage local --path tests/test-event.json",
    "invoke:api": "serverless invoke -f createRecord --stage local --path tests/test-api.json",
    "info": "serverless info --stage local",
    "docker:up": "docker-compose up -d",
    "docker:down": "docker-compose down",
    "docker:logs": "docker-compose logs -f localstack"
  },
  "keywords": [
    "serverless",
    "localstack",
    "aws",
    "lambda",
    "nodejs",
    "faas"
  ],
  "author": "Aluno PUC Minas",
  "license": "MIT",
  "dependencies": {
    "aws-sdk": "^2.1691.0",
    "uuid": "^9.0.1"
  },
  "devDependencies": {
    "serverless": "^3.38.0",
    "serverless-localstack": "^1.2.0",
    "serverless-offline": "^13.8.1",
    "@types/node": "^20.17.0",
    "@types/aws-lambda": "^8.10.145",
    "eslint": "^8.57.1"
  },
  "engines": {
    "node": ">=18.0.0",
    "npm": ">=9.0.0"
  }
}
```

### 7.2 VariÃ¡veis de Ambiente (`.env`)

```env
# LocalStack Configuration
LOCALSTACK_ENDPOINT=http://localhost:4566
AWS_ACCESS_KEY_ID=test
AWS_SECRET_ACCESS_KEY=test
AWS_DEFAULT_REGION=us-east-1

# Service Configuration
TABLE_NAME=ProcessedData
BUCKET_NAME=data-processing-bucket
TOPIC_NAME=data-processing-notifications
STAGE=local

# Node.js Configuration
NODE_ENV=development
```

### 7.3 GitIgnore (`.gitignore`)

```gitignore
# Node.js
node_modules/
npm-debug.log*
yarn-error.log*
package-lock.json
yarn.lock

# Serverless Framework
.serverless/
.serverless-offline/
.build/

# Environment
.env
.env.local
.env.*.local

# IDE
.vscode/
.idea/
*.swp
*.swo
*~

# OS
.DS_Store
Thumbs.db

# Logs
logs/
*.log

# Temporary files
tmp/
temp/
*.tmp

# AWS
credentials
config
```

---

## **PASSO 8: Deploy e ExecuÃ§Ã£o**

### 8.1 Setup Completo Automatizado

```bash
# MÃ©todo 1: Usando script de setup
npm run setup

# MÃ©todo 2: Passo a passo manual
npm install
docker-compose up -d
sleep 30
serverless deploy --stage local --verbose
```

### 8.2 Verificar Recursos Criados

```bash
# Verificar bucket S3
aws --endpoint-url=http://localhost:4566 s3 ls

# Listar tabelas DynamoDB
aws --endpoint-url=http://localhost:4566 dynamodb list-tables

# Listar funÃ§Ãµes Lambda
aws --endpoint-url=http://localhost:4566 lambda list-functions --query 'Functions[*].FunctionName'

# Listar tÃ³picos SNS
aws --endpoint-url=http://localhost:4566 sns list-topics

# Ver informaÃ§Ãµes do stack
serverless info --stage local
```

### 8.3 Testar Pipeline Completo

```bash
# MÃ©todo 1: Script automatizado (recomendado)
npm test

# MÃ©todo 2: Teste manual
# Upload de arquivo
aws --endpoint-url=http://localhost:4566 s3 cp data/input/produtos.csv s3://data-processing-bucket/input/

# Aguardar processamento (10-20 segundos)
sleep 15

# Verificar dados processados
aws --endpoint-url=http://localhost:4566 dynamodb scan --table-name ProcessedData --query 'Items[*].[id.S, nome.S, preco.N]' --output table

# Ver logs da Lambda
serverless logs -f dataProcessor --stage local --tail
```

### 8.4 Testar API REST

```bash
# MÃ©todo 1: Via Serverless
serverless invoke -f createRecord --stage local --path tests/test-api.json

# MÃ©todo 2: Via curl (requer endpoint do API Gateway)
# Primeiro, obter URL do API Gateway
serverless info --stage local

# EntÃ£o fazer requisiÃ§Ã£o
curl -X POST http://localhost:4566/restapis/{api-id}/local/_user_request_/records \
  -H "Content-Type: application/json" \
  -d '{"nome":"Teste cURL","preco":150.00}'
```

---

## **PASSO 9: Monitoramento e Debug**

### 9.1 Visualizar Logs em Tempo Real

```bash
# Logs da funÃ§Ã£o dataProcessor
serverless logs -f dataProcessor --stage local --tail

# Logs do LocalStack
docker-compose logs -f localstack

# Logs especÃ­ficos do Lambda no container
docker logs localstack-serverless-lab -f
```

### 9.2 Invocar FunÃ§Ã£o Manualmente

```bash
# Invocar com evento de teste
serverless invoke -f dataProcessor --stage local --path tests/test-event.json

# Invocar localmente (sem deploy)
serverless invoke local -f dataProcessor --path tests/test-event.json

# Invocar API
serverless invoke -f createRecord --stage local --path tests/test-api.json
```

### 9.3 Consultas DynamoDB

```bash
# Scan completo
aws --endpoint-url=http://localhost:4566 dynamodb scan --table-name ProcessedData

# Scan com projeÃ§Ã£o de campos especÃ­ficos
aws --endpoint-url=http://localhost:4566 dynamodb scan --table-name ProcessedData \
  --projection-expression "id, nome, preco, source_file"

# Contar items
aws --endpoint-url=http://localhost:4566 dynamodb scan --table-name ProcessedData --select COUNT

# Query especÃ­fica (requer partition key)
aws --endpoint-url=http://localhost:4566 dynamodb query --table-name ProcessedData \
  --key-condition-expression "id = :id" \
  --expression-attribute-values '{":id":{"S":"1"}}'
```

### 9.4 OperaÃ§Ãµes S3

```bash
# Listar arquivos
aws --endpoint-url=http://localhost:4566 s3 ls s3://data-processing-bucket/input/

# Ver conteÃºdo de arquivo
aws --endpoint-url=http://localhost:4566 s3 cp s3://data-processing-bucket/input/produtos.csv -

# Deletar arquivo
aws --endpoint-url=http://localhost:4566 s3 rm s3://data-processing-bucket/input/produtos.csv
```

---

## **PASSO 10: AnÃ¡lise e DocumentaÃ§Ã£o**

### 10.1 AnÃ¡lise Arquitetural

**CaracterÃ­sticas Implementadas:**
- âœ… Arquitetura event-driven completamente serverless
- âœ… Pipeline de processamento automÃ¡tico (S3 â†’ Lambda â†’ DynamoDB)
- âœ… API REST serverless com Lambda + API Gateway
- âœ… NotificaÃ§Ãµes pub/sub com SNS
- âœ… Infrastructure as Code com Serverless Framework
- âœ… Desenvolvimento local com LocalStack (sem custos AWS)

**MÃ©tricas de Performance Esperadas:**

| MÃ©trica | Valor | ObservaÃ§Ãµes |
|---------|-------|-------------|
| **Cold Start** | 500-1500ms | Primeira invocaÃ§Ã£o apÃ³s deploy |
| **Warm Start** | 5-50ms | InvocaÃ§Ãµes subsequentes |
| **Throughput** | Ilimitado | Auto-scaling automÃ¡tico |
| **ConcorrÃªncia** | 1000 (AWS default) | ConfigurÃ¡vel |
| **Timeout** | 60s (configurado) | MÃ¡ximo 15 minutos |
| **MemÃ³ria** | 256MB | AjustÃ¡vel por funÃ§Ã£o |

**Vantagens Demonstradas:**

1. **Pay-per-use**: Custo zero quando nÃ£o hÃ¡ requisiÃ§Ãµes
2. **Auto-scaling**: Escala automaticamente de 0 a milhÃµes
3. **Zero Server Management**: Infraestrutura gerenciada
4. **Event-driven**: ReaÃ§Ã£o automÃ¡tica a eventos S3
5. **Development Velocity**: Foco em cÃ³digo de negÃ³cio

**LimitaÃ§Ãµes Identificadas:**

1. **Cold Start Latency**: ~1 segundo inicial
2. **Vendor Lock-in**: Forte dependÃªncia de AWS
3. **Debugging Complexity**: Rastreamento distribuÃ­do complexo
4. **Stateless**: Cada invocaÃ§Ã£o Ã© independente
5. **Timeout Limits**: 15 minutos mÃ¡ximo por funÃ§Ã£o

### 10.2 ComparaÃ§Ã£o com Arquiteturas Anteriores

| Aspecto | Tradicional (Roteiro 1) | gRPC (Roteiro 2) | Serverless (Roteiro 4) |
|---------|-------------------------|------------------|------------------------|
| **Infraestrutura** | Servidor sempre ativo | Servidor sempre ativo | Sem servidor |
| **Custo** | Fixo (24/7) | Fixo (24/7) | Por execuÃ§Ã£o |
| **Escalabilidade** | Manual/Limitada | Manual/Boa | AutomÃ¡tica/Infinita |
| **ManutenÃ§Ã£o** | Alta | Alta | MÃ­nima |
| **Cold Start** | N/A | N/A | 500-1500ms |
| **Throughput** | Limitado | Alto | Ilimitado |
| **Complexidade** | Baixa | MÃ©dia | MÃ©dia-Alta |
| **Debugging** | FÃ¡cil | MÃ©dio | DifÃ­cil |
| **Event-driven** | Manual | Manual | Nativo |
| **Vendor Lock-in** | Baixo | Baixo | Alto |

### 10.3 Quando Usar Serverless

**âœ… Use Serverless quando:**

1. **Workloads Intermitentes**
   ```
   - Processamento batch noturno
   - Webhooks esporÃ¡dicos
   - Tarefas agendadas
   - Picos de trÃ¡fego imprevisÃ­veis
   ```

2. **Event-driven Applications**
   ```
   - Processamento de uploads
   - Streams de dados
   - IoT data processing
   - Real-time file processing
   ```

3. **Microservices Stateless**
   ```
   - APIs REST simples
   - Data transformation
   - Image processing
   - Notification services
   ```

4. **PrototipaÃ§Ã£o RÃ¡pida**
   ```
   - MVPs
   - Proof of concepts
   - Experimentos
   ```

**âŒ Evite Serverless quando:**

1. **AplicaÃ§Ãµes Stateful**
   ```
   - WebSocket servers
   - Game servers
   - Long-running connections
   ```

2. **Workloads Constantes**
   ```
   - TrÃ¡fego 24/7 constante
   - Background workers contÃ­nuos
   - Pode ser mais caro que servidor dedicado
   ```

3. **Processamento de Longa DuraÃ§Ã£o**
   ```
   - Tarefas > 15 minutos
   - Video encoding complexo
   - Large batch processing
   ```

4. **Requisitos BaixÃ­ssimos de LatÃªncia**
   ```
   - Trading algorithms
   - Real-time gaming
   - Cold start inaceitÃ¡vel
   ```

### 10.4 Best Practices Implementadas

**1. SeparaÃ§Ã£o de Responsabilidades**
```javascript
// âœ… Bom: FunÃ§Ãµes focadas
- dataProcessor: Apenas processa CSV
- createRecord: Apenas cria registros

// âŒ Evitar: FunÃ§Ãµes monolÃ­ticas que fazem tudo
```

**2. ConfiguraÃ§Ã£o Externa**
```javascript
// âœ… Bom: VariÃ¡veis de ambiente
const tableName = process.env.TABLE_NAME;

// âŒ Evitar: Hardcoded
const tableName = 'ProcessedData';
```

**3. Tratamento de Erros Robusto**
```javascript
// âœ… Bom: Try-catch com logging
try {
  await putItem(item);
} catch (error) {
  console.error('Erro:', error);
  await notifyError(error);
  throw error;
}
```

**4. PrincÃ­pio de Menor PrivilÃ©gio (IAM)**
```yaml
# âœ… Bom: Apenas permissÃµes necessÃ¡rias
- Effect: Allow
  Action:
    - dynamodb:PutItem
  Resource: !GetAtt ProcessedDataTable.Arn

# âŒ Evitar: PermissÃµes amplas
- Effect: Allow
  Action: '*'
  Resource: '*'
```

**5. Timeout e Memory Sizing**
```yaml
# âœ… Bom: Ajustado para workload
timeout: 60
memorySize: 256

# âŒ Evitar: Valores padrÃ£o sem otimizaÃ§Ã£o
```

### 10.5 Troubleshooting Comum

**Problema 1: Lambda nÃ£o Ã© invocada pelo S3**
```bash
# SoluÃ§Ã£o: Recriar trigger
serverless deploy --stage local --force

# Verificar permissÃµes
aws --endpoint-url=http://localhost:4566 lambda get-policy --function-name DataProcessorFunction
```

**Problema 2: Erro "Cannot find module"**
```bash
# SoluÃ§Ã£o: Reinstalar dependÃªncias
rm -rf node_modules
npm install

# Redeploy
serverless deploy --stage local
```

**Problema 3: LocalStack nÃ£o inicia**
```bash
# SoluÃ§Ã£o: Limpar e reiniciar
docker-compose down -v
docker-compose up -d

# Aguardar inicializaÃ§Ã£o
sleep 30
```

**Problema 4: DynamoDB nÃ£o recebe dados**
```bash
# Verificar logs da Lambda
serverless logs -f dataProcessor --stage local

# Verificar se funÃ§Ã£o foi invocada
aws --endpoint-url=http://localhost:4566 lambda get-function --function-name DataProcessorFunction

# Testar manualmente
serverless invoke -f dataProcessor --stage local --path tests/test-event.json
```

---

## **ExercÃ­cios Complementares**

1. **Implementar Retry Logic**: Adicionar lÃ³gica de retry com exponential backoff para falhas no DynamoDB
   
2. **Dead Letter Queue**: Configurar DLQ para processar eventos com falha
   
3. **MÃ©tricas Customizadas**: Enviar mÃ©tricas customizadas para CloudWatch
   
4. **Caching**: Implementar caching de leituras frequentes do DynamoDB
   
5. **Batch Processing**: Modificar para processar mÃºltiplos arquivos em paralelo
   
6. **API Authentication**: Adicionar autenticaÃ§Ã£o JWT ou API Keys no API Gateway
   
7. **Data Validation**: Implementar validaÃ§Ã£o de schema mais robusta com Joi ou Ajv
   
8. **Lambda Layers**: Criar Lambda Layer para cÃ³digo compartilhado
   
9. **Step Functions**: Orquestrar pipeline complexo com AWS Step Functions
   
10. **Performance Monitoring**: Implementar tracing distribuÃ­do com X-Ray

---

## **EntregÃ¡veis**

### Checklist de ImplementaÃ§Ã£o

**ConfiguraÃ§Ã£o:**
- [ ] LocalStack rodando via Docker Compose
- [ ] Serverless Framework configurado corretamente
- [ ] Todas as dependÃªncias Node.js instaladas
- [ ] VariÃ¡veis de ambiente configuradas

**FunÃ§Ãµes Lambda:**
- [ ] dataProcessor implementada e funcional
- [ ] createRecord implementada e funcional
- [ ] Helpers (DynamoDB, S3, SNS) implementados
- [ ] Tratamento de erros robusto em todas funÃ§Ãµes

**Infraestrutura:**
- [ ] Bucket S3 criado
- [ ] Tabela DynamoDB criada
- [ ] TÃ³pico SNS criado
- [ ] API Gateway configurado
- [ ] Triggers S3 â†’ Lambda funcionando

**Testes:**
- [ ] Upload de CSV dispara Lambda automaticamente
- [ ] Dados sÃ£o processados e salvos no DynamoDB
- [ ] NotificaÃ§Ãµes SNS sÃ£o enviadas
- [ ] API REST responde corretamente
- [ ] Script de teste automatizado executa sem erros

**DocumentaÃ§Ã£o:**
- [ ] README.md completo
- [ ] ComentÃ¡rios no cÃ³digo
- [ ] Diagrama de arquitetura
- [ ] AnÃ¡lise comparativa com outras arquiteturas
- [ ] IdentificaÃ§Ã£o de casos de uso apropriados

---

## **Comandos Ãšteis**

### Deploy e RemoÃ§Ã£o
```bash
# Deploy completo
npm run deploy
# ou
serverless deploy --stage local

# Deploy apenas de uma funÃ§Ã£o
serverless deploy function -f dataProcessor --stage local

# Remover tudo
npm run remove
# ou
serverless remove --stage local
```

### Testes e Debugging
```bash
# Executar teste automatizado
npm test

# Ver logs em tempo real
npm run logs:tail

# Invocar funÃ§Ã£o manualmente
npm run invoke

# Testar API
npm run invoke:api

# Ver informaÃ§Ãµes do stack
npm run info
```

### Docker/LocalStack
```bash
# Iniciar LocalStack
npm run docker:up

# Parar LocalStack
npm run docker:down

# Ver logs do LocalStack
npm run docker:logs
```

### AWS CLI (LocalStack)
```bash
# S3
aws --endpoint-url=http://localhost:4566 s3 ls
aws --endpoint-url=http://localhost:4566 s3 cp arquivo.csv s3://data-processing-bucket/input/
aws --endpoint-url=http://localhost:4566 s3 rm s3://data-processing-bucket/input/arquivo.csv

# DynamoDB
aws --endpoint-url=http://localhost:4566 dynamodb list-tables
aws --endpoint-url=http://localhost:4566 dynamodb scan --table-name ProcessedData
aws --endpoint-url=http://localhost:4566 dynamodb describe-table --table-name ProcessedData

# Lambda
aws --endpoint-url=http://localhost:4566 lambda list-functions
aws --endpoint-url=http://localhost:4566 lambda get-function --function-name DataProcessorFunction
aws --endpoint-url=http://localhost:4566 lambda invoke --function-name DataProcessorFunction output.json

# SNS
aws --endpoint-url=http://localhost:4566 sns list-topics
aws --endpoint-url=http://localhost:4566 sns list-subscriptions
```

---

## **ConclusÃ£o**

Este roteiro demonstrou a implementaÃ§Ã£o completa de uma arquitetura serverless usando AWS Lambda, S3, DynamoDB e SNS, com desenvolvimento local via LocalStack. Os principais conceitos abordados incluem:

1. **Function as a Service (FaaS)**: ExecuÃ§Ã£o de cÃ³digo sem gerenciar servidores
2. **Event-driven Architecture**: ReaÃ§Ã£o automÃ¡tica a eventos do sistema
3. **Infrastructure as Code**: DefiniÃ§Ã£o declarativa de toda infraestrutura
4. **Pay-per-use Model**: Custos baseados apenas em execuÃ§Ãµes reais
5. **Auto-scaling**: Escalamento transparente e automÃ¡tico

**PrÃ³ximos Passos:**

- Experimentar com outros triggers (DynamoDB Streams, SQS, etc)
- Implementar orquestraÃ§Ã£o complexa com Step Functions
- Adicionar monitoramento e alertas com CloudWatch
- Explorar Lambda Layers para otimizaÃ§Ã£o
- Migrar para produÃ§Ã£o na AWS real

---

## **ReferÃªncias**

<sup>[1]</sup> ROBERTS, Mike. **Serverless Architectures**. Martin Fowler, 2018. DisponÃ­vel em: https://martinfowler.com/articles/serverless.html

<sup>[2]</sup> BALDINI, Ioana et al. **Serverless Computing: Current Trends and Open Problems**. Research Advances in Cloud Computing, Singapore: Springer, 2017.

<sup>[3]</sup> **LocalStack Documentation**. DisponÃ­vel em: https://docs.localstack.cloud/

**AWS Lambda Developer Guide**. Amazon Web Services. DisponÃ­vel em: https://docs.aws.amazon.com/lambda/

**Serverless Framework Documentation**. DisponÃ­vel em: https://www.serverless.com/framework/docs

**KLEPPMANN, Martin.** Designing Data-Intensive Applications. O'Reilly Media, 2017.
